{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4ef4d45-1e9a-4091-ac9b-329387714025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import lightfm\n",
    "\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.connector.pandas_tools import write_pandas\n",
    "import snowflake.snowpark.functions as f\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import lightfm\n",
    "from lightfm import LightFM\n",
    "from lightfm.data import Dataset\n",
    "from lightfm.cross_validation import random_train_test_split\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k\n",
    "import numpy as np\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k, auc_score\n",
    "import ast\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os \n",
    "\n",
    "from TopicAnalysis import TopicAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "720b4a5e-269b-4d6f-90d0-c0062cf059b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONNECTION_PARAMETERS = {}\n",
    "\n",
    "session = Session.builder.configs(CONNECTION_PARAMETERS).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc4b51e2-2983-4bd4-bd53-5c1bb4c471cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_recommender(session: Session, file_prefix: str) -> None:\n",
    "    batch_size = 10**7\n",
    "    num_threads = os.cpu_count()\n",
    "    \n",
    "    def get_data_count():\n",
    "        base_data = session.table('MODELING.RECOMMENDER_TRAIN')\n",
    "        return base_data.count()\n",
    "    \n",
    "    def get_batch_data(num, offset):\n",
    "        base_data = session.table('MODELING.RECOMMENDER_TRAIN')\n",
    "        base_data = base_data.limit(num, offset=offset)\n",
    "        return base_data.toPandas()\n",
    "    \n",
    "    def get_emails():\n",
    "        base_data = session.table('MODELING.RECOMMENDER_TRAIN')\n",
    "        base_data = base_data.select('EMAIL')\n",
    "        base_data = base_data.distinct()\n",
    "        return base_data.toPandas()\n",
    "    \n",
    "    def get_campaign_ids():\n",
    "        result = session.sql(\"\"\"SELECT DISTINCT CAMPAIGN_ID, SCORES FROM MODELING.RECOMMENDER_TRAIN\"\"\")\n",
    "        df = result.toPandas()\n",
    "        df['SCORES'] = df['SCORES'].apply(lambda x: [float(x) for x in x.split(',')])\n",
    "        return df\n",
    "        \n",
    "    class LightModel:\n",
    "        def __init__(self, users, items, feature_list):\n",
    "            self.dataset = Dataset(item_identity_features=False)\n",
    "            self.dataset.fit(users=users, items=items, item_features=[i for i in range(len(feature_list[0]))])\n",
    "            self.users = users\n",
    "            self.items = items\n",
    "            self.feature_list = feature_list\n",
    "            feature_dicts = []\n",
    "            for features in feature_list:\n",
    "                feature_dicts.append({i: float(feature) for i, feature in enumerate(features)})\n",
    "            self.feature_dicts = feature_dicts\n",
    "            self.item_features = self.dataset.build_item_features(zip(items, feature_dicts))\n",
    "            self.model = LightFM(loss='warp')\n",
    "            \n",
    "        def add_data(self, users, items):        \n",
    "            interactions, _ = self.dataset.build_interactions(zip(users, items))\n",
    "            self.model.fit_partial(interactions, item_features=self.item_features, num_threads=num_threads)\n",
    "    \n",
    "        def predict(self, feature_list):\n",
    "            new_id = max(self.items) * 2\n",
    "            new_features = {i: float(feature) for i, feature in enumerate(feature_list)}\n",
    "            self.dataset.fit_partial(users=None, items=[new_id])\n",
    "            new_feature_dicts = self.feature_dicts + [new_features]\n",
    "            new_items = list(self.items) + [new_id]\n",
    "            item_features = model.dataset.build_item_features(zip(new_items, new_feature_dicts))\n",
    "    \n",
    "            user_mapping = self.dataset.mapping()[0]\n",
    "            item_mapping = self.dataset.mapping()[2]\n",
    "    \n",
    "            all_users = list(user_mapping.values())\n",
    "            item_expanded = [item_mapping[new_id]] * len(all_users)\n",
    "            results = self.model.predict(list(user_mapping.values()), item_ids=item_expanded, item_features=item_features, num_threads=num_threads)\n",
    "    \n",
    "            all_emails = list(user_mapping.keys())\n",
    "            \n",
    "            return list(zip(all_emails, results))\n",
    "\n",
    "    id_score = get_campaign_ids()\n",
    "    emails = get_emails()\n",
    "    num_rows = get_data_count()\n",
    "\n",
    "    ids = id_score['CAMPAIGN_ID']\n",
    "    scores = id_score['SCORES']\n",
    "    unique_emails = emails['EMAIL']\n",
    "    \n",
    "    model = LightModel(unique_emails, ids, scores)\n",
    "\n",
    "    num_batches = num_rows // batch_size + 1\n",
    "    rows = []\n",
    "    for i in range(num_batches):\n",
    "        df = get_batch_data(batch_size, batch_size * i)\n",
    "        print(f\"Completed {i}/{num_batches}\")\n",
    "        try:\n",
    "            model.add_data(df['EMAIL'].values, df['CAMPAIGN_ID'].values)\n",
    "        except:\n",
    "            print('Exception occurred')\n",
    "            try:\n",
    "                df_filtered = df[df['EMAIL'].isin(unique_emails['EMAIL'])]\n",
    "                model.add_data(df_filtered['EMAIL'].values, df_filtered['CAMPAIGN_ID'].values)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    joblib.dump(model.model, f'/tmp/recommender.joblib')\n",
    "    joblib.dump(model.dataset, f'/tmp/dataset.joblib')\n",
    "    \n",
    "    session.file.put(\n",
    "        f'/tmp/recommender.joblib',\n",
    "        f\"@MODELS/recommender/{file_prefix}/\",\n",
    "        auto_compress=False,\n",
    "        overwrite=True\n",
    "    )\n",
    "    session.file.put(\n",
    "        f'/tmp/dataset.joblib',\n",
    "        f\"@MODELS/recommender/{file_prefix}/\",\n",
    "        auto_compress=False,\n",
    "        overwrite=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de60b6dc-3d2d-421e-a469-ea6271de853e",
   "metadata": {},
   "outputs": [],
   "source": [
    "registered_function = session.sproc.register(\n",
    "        func=train_recommender,\n",
    "        name=\"train_recommender\",\n",
    "        is_permanent=True,\n",
    "        replace=True,\n",
    "        stage_location=\"@MODELS\",\n",
    "        packages=[\"snowflake-snowpark-python\", \"pandas\",  \"numpy\", \"lightfm\", \"joblib\", \"scikit-learn\"],\n",
    "        execute_as='CALLER'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "872e54f5-9f0f-4e9b-adb6-36802834a9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(TRAIN_RECOMMENDER=None)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.sql(\"\"\"CALL MODELING.TRAIN_RECOMMENDER('test_0')\"\"\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "daca15c4-9acf-4769-8974-f6bdc3e5c68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GetResult(file='test_0/dataset.joblib', size=89670100, status='DOWNLOADED', message=''),\n",
       " GetResult(file='test_0/recommender.joblib', size=309063339, status='DOWNLOADED', message='')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.file.get('@MODELS/recommender/test_0/', 'files/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
